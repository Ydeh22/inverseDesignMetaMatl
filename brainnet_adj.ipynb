{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brainnet-adj.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6vpTxCeJhSLQQiQoYe1he",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taechanha/inverseDesignMetaMatl/blob/main/brainnet_adj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reL3tbAh5_tv",
        "outputId": "18b27aac-fc03-4394-c31a-b19260cb0cd6"
      },
      "source": [
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "###################### FROM HERE ######################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f = open(\"/content/dataset_2.txt\", 'r')\n",
        "data = []\n",
        "length = 0\n",
        "for i in f:\n",
        "  new = []\n",
        "  new.append(i)\n",
        "  data.append(new)\n",
        "\n",
        "  # length of dataset\n",
        "  length += 1\n",
        "\n",
        "f.close()\n",
        "\n",
        "# create dataset from data\n",
        "dataset = []\n",
        "for i in range(length):\n",
        "  new = []\n",
        "  for j in data[i][0].split(','):\n",
        "    new.append(float(j))\n",
        "  dataset.append(new)\n",
        "\n",
        "\n",
        "# trim out label from dataset\n",
        "# Ex Ey Ez\n",
        "label = []\n",
        "new = []\n",
        "for line in dataset:\n",
        "  tmp = []\n",
        "  tmp.append(line.pop(-1))\n",
        "  tmp.append(line.pop(-1))\n",
        "  tmp.append(line.pop(-1))\n",
        "  tmp.reverse()\n",
        "  label.append(tmp)\n",
        "\n",
        "print(\"label.shape: \", np.array(label).shape)\n",
        "\n",
        "\n",
        "# create edge_index\n",
        "edge_mat = np.zeros(shape=(27,27))\n",
        "edge_index = []\n",
        "\n",
        "for e in range(len(dataset)):\n",
        "  for i in range(0, 27):\n",
        "    for j in range(i+1, 27):\n",
        "      edge_mat[i][j] = dataset[e].pop(0)\n",
        "  edge_index.append(edge_mat + edge_mat.T)\n",
        "\n",
        "\n",
        "# whole dataset to Tensor & train/test split\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "edge_index = torch.FloatTensor(edge_index)\n",
        "label = torch.FloatTensor(label)\n",
        "\n",
        "split = int(length * 0.8)\n",
        "\n",
        "x_train = edge_index[:split]\n",
        "y_train = label[:split]\n",
        "x_val = edge_index[split:]\n",
        "y_val = label[split:]\n",
        "\n",
        "print(\"x_train, y_train, x_val shape: \", x_train.shape, y_train.shape, x_val.shape)\n",
        "\n",
        "# create torch dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, label, dataset, transform=None, target_transform=None):\n",
        "        self.labels = label\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.dataset[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return data, label\n",
        "\n",
        "# create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_data   = CustomDataset(label=y_train, dataset=x_train)\n",
        "test_data       = CustomDataset(label=y_val, dataset=x_val)\n",
        "train_loader    = DataLoader(training_data, batch_size=4, shuffle=True)\n",
        "test_loader     = DataLoader(test_data, batch_size=4, shuffle=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label.shape:  (2000, 3)\n",
            "x_train, y_train, x_val shape:  torch.Size([1600, 27, 27]) torch.Size([1600, 3]) torch.Size([400, 27, 27])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoZ3VUQU9D0e",
        "outputId": "73ae2cc8-2a21-477e-c43d-46e121716e13"
      },
      "source": [
        "x_train = edge_index[:split]\n",
        "y_train = label[:split][:, 0]\n",
        "x_val = edge_index[split:]\n",
        "y_val = label[split:][:, 0]\n",
        "\n",
        "print(\"x_train, y_train, x_val shape: \", x_train.shape, y_train.shape, x_val.shape)\n",
        "\n",
        "# create torch dataset\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, label, dataset, transform=None, target_transform=None):\n",
        "        self.labels = label\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.dataset[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return data, label\n",
        "\n",
        "# create DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_data   = CustomDataset(label=y_train, dataset=x_train)\n",
        "test_data       = CustomDataset(label=y_val, dataset=x_val)\n",
        "train_loader    = DataLoader(training_data, batch_size=4, shuffle=True)\n",
        "test_loader     = DataLoader(test_data, batch_size=4, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train, y_train, x_val shape:  torch.Size([1600, 27, 27]) torch.Size([1600]) torch.Size([400, 27, 27])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZKtXRX9JNA"
      },
      "source": [
        "def r2(output, target):\n",
        "    target_mean = torch.mean(target)\n",
        "    ss_tot = torch.sum((target - target_mean) ** 2)\n",
        "    ss_res = torch.sum((target - output) ** 2)\n",
        "    r2 = 1 - ss_res / ss_tot\n",
        "    return r2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN_HFkKg7lFD"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "_cJsDYd97e1Z",
        "outputId": "e2e5b94d-8fd5-4a3c-bb88-091247114978"
      },
      "source": [
        "# the number of trainable parameter\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f86e4ac19a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# the number of trainable parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj8IgfNz9AZs"
      },
      "source": [
        "def train(model, train_losses, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda().float(), y.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        o = model(x)\n",
        "        \n",
        "        loss = loss_function(o.squeeze(), y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print('====> Epoch: {} loss: {:.4f}'.format(e, train_loss / len(train_loader)))\n",
        "    train_losses.append(train_loss / len(train_loader))\n",
        "\n",
        "def test(model, val_losses):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda().float(), y.cuda()       \n",
        "            o = model(x)\n",
        "            loss = loss_function(o.squeeze(), y)\n",
        "            \n",
        "            test_loss += loss.item()\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss / len(test_loader)))\n",
        "    val_losses.append(test_loss / len(test_loader))\n",
        "\n",
        "def test_pred(model):\n",
        "    y_pred = []\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda().float(), y.cuda()       \n",
        "            o = model(x)\n",
        "            y_pred.append(o)\n",
        "\n",
        "            loss = loss_function(o.squeeze(), y)\n",
        "            test_loss += loss.item()\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss / len(test_loader)))\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt128s485-OM",
        "outputId": "2e2df596-9c93-4acf-c010-68a933108b6c"
      },
      "source": [
        "class E2EBlock(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, bias=False):\n",
        "        super(E2EBlock, self).__init__()\n",
        "        self.cnn1 = torch.nn.Conv2d(in_dim, out_dim, (1, 27), bias=bias)\n",
        "        self.cnn2 = torch.nn.Conv2d(in_dim, out_dim, (27, 1), bias=bias)\n",
        "\n",
        "        #nn.init.xavier_uniform_(self.cnn2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = self.cnn1(x)\n",
        "        b = self.cnn2(x)\n",
        "\n",
        "        return torch.cat([a]*27, 3) + torch.cat([b]*27, 2)\n",
        "\n",
        "class BrainNetCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrainNetCNN, self).__init__()\n",
        "        \n",
        "        self.e2econv1 = E2EBlock(1, 8, bias=True)\n",
        "        #self.conv5_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.E2N = torch.nn.Conv2d(8, 1, (1, 27))\n",
        "        self.N2G = torch.nn.Conv2d(1, 32, (27, 1))\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(32, 16)\n",
        "        self.fc2 = torch.nn.Linear(16, 1)\n",
        "        #self.dense5 = torch.nn.Linear(16, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = F.relu(self.e2econv1(x))\n",
        "        #out = self.conv5_bn(out)\n",
        "        #out = F.max_pool2d(out, 2)  # 적용한 마지막 output kernel size, kernel 영향 + 풀링 영향으로 줄어든 사이즈\n",
        "\n",
        "        x = F.relu(self.E2N(x))\n",
        "        x = F.relu(self.N2G(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        #x = self.dense4_bn(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def weights_init(m):\n",
        "    #if isinstance(m, nn.Conv2d):\n",
        "    #    nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "        #m.bias.data[0] = 9.0844\n",
        "        \n",
        "        #if m.bias is not None:\n",
        "        #  nn.init.constant_(m.bias.data, 10)\n",
        "        #nn.init.xavier_normal_(m.bias.data)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = BrainNetCNN().cuda()\n",
        "model.apply(weights_init)\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BrainNetCNN(\n",
            "  (e2econv1): E2EBlock(\n",
            "    (cnn1): Conv2d(1, 8, kernel_size=(1, 27), stride=(1, 1))\n",
            "    (cnn2): Conv2d(1, 8, kernel_size=(27, 1), stride=(1, 1))\n",
            "  )\n",
            "  (E2N): Conv2d(8, 1, kernel_size=(1, 27), stride=(1, 1))\n",
            "  (N2G): Conv2d(1, 32, kernel_size=(27, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L5G0gDTg7u6q",
        "outputId": "3263db32-d922-45dd-8e2f-a44f8a3965a1"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)#5e-6\n",
        "loss_function = nn.MSELoss()\n",
        "epochs = 100\n",
        "\n",
        "# for loss plot\n",
        "tloss = []\n",
        "vloss = []\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    train(model, tloss, e)\n",
        "    test(model, vloss)\n",
        "\n",
        "y_pred = test_pred(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 loss: 95.5758\n",
            "====> Test set loss: 34.7213\n",
            "====> Epoch: 2 loss: 33.3929\n",
            "====> Test set loss: 29.9060\n",
            "====> Epoch: 3 loss: 31.7342\n",
            "====> Test set loss: 28.8221\n",
            "====> Epoch: 4 loss: 30.4074\n",
            "====> Test set loss: 27.9616\n",
            "====> Epoch: 5 loss: 29.2771\n",
            "====> Test set loss: 26.8976\n",
            "====> Epoch: 6 loss: 27.9491\n",
            "====> Test set loss: 26.0045\n",
            "====> Epoch: 7 loss: 26.5714\n",
            "====> Test set loss: 24.8799\n",
            "====> Epoch: 8 loss: 25.2139\n",
            "====> Test set loss: 23.7241\n",
            "====> Epoch: 9 loss: 23.9510\n",
            "====> Test set loss: 22.5517\n",
            "====> Epoch: 10 loss: 22.5146\n",
            "====> Test set loss: 21.6697\n",
            "====> Epoch: 11 loss: 21.2679\n",
            "====> Test set loss: 20.3339\n",
            "====> Epoch: 12 loss: 19.9937\n",
            "====> Test set loss: 19.2776\n",
            "====> Epoch: 13 loss: 18.6997\n",
            "====> Test set loss: 18.5564\n",
            "====> Epoch: 14 loss: 17.5193\n",
            "====> Test set loss: 17.3858\n",
            "====> Epoch: 15 loss: 16.4518\n",
            "====> Test set loss: 16.5060\n",
            "====> Epoch: 16 loss: 15.4190\n",
            "====> Test set loss: 15.6349\n",
            "====> Epoch: 17 loss: 14.4451\n",
            "====> Test set loss: 14.8079\n",
            "====> Epoch: 18 loss: 13.5122\n",
            "====> Test set loss: 13.9463\n",
            "====> Epoch: 19 loss: 12.5314\n",
            "====> Test set loss: 13.0701\n",
            "====> Epoch: 20 loss: 11.5805\n",
            "====> Test set loss: 12.3324\n",
            "====> Epoch: 21 loss: 10.6807\n",
            "====> Test set loss: 11.3610\n",
            "====> Epoch: 22 loss: 9.8155\n",
            "====> Test set loss: 10.5289\n",
            "====> Epoch: 23 loss: 9.0440\n",
            "====> Test set loss: 9.8885\n",
            "====> Epoch: 24 loss: 8.3643\n",
            "====> Test set loss: 9.3066\n",
            "====> Epoch: 25 loss: 7.7895\n",
            "====> Test set loss: 8.7810\n",
            "====> Epoch: 26 loss: 7.3849\n",
            "====> Test set loss: 8.4510\n",
            "====> Epoch: 27 loss: 7.0671\n",
            "====> Test set loss: 8.2155\n",
            "====> Epoch: 28 loss: 6.8133\n",
            "====> Test set loss: 8.0905\n",
            "====> Epoch: 29 loss: 6.5569\n",
            "====> Test set loss: 7.8960\n",
            "====> Epoch: 30 loss: 6.4430\n",
            "====> Test set loss: 7.9081\n",
            "====> Epoch: 31 loss: 6.2749\n",
            "====> Test set loss: 7.7489\n",
            "====> Epoch: 32 loss: 6.2003\n",
            "====> Test set loss: 7.6470\n",
            "====> Epoch: 33 loss: 6.0588\n",
            "====> Test set loss: 7.5967\n",
            "====> Epoch: 34 loss: 5.9553\n",
            "====> Test set loss: 7.6430\n",
            "====> Epoch: 35 loss: 5.9431\n",
            "====> Test set loss: 7.5619\n",
            "====> Epoch: 36 loss: 5.8545\n",
            "====> Test set loss: 7.7719\n",
            "====> Epoch: 37 loss: 5.8110\n",
            "====> Test set loss: 7.6237\n",
            "====> Epoch: 38 loss: 5.7351\n",
            "====> Test set loss: 7.5111\n",
            "====> Epoch: 39 loss: 5.6839\n",
            "====> Test set loss: 7.4531\n",
            "====> Epoch: 40 loss: 5.6274\n",
            "====> Test set loss: 7.4256\n",
            "====> Epoch: 41 loss: 5.5506\n",
            "====> Test set loss: 7.4480\n",
            "====> Epoch: 42 loss: 5.5081\n",
            "====> Test set loss: 7.7867\n",
            "====> Epoch: 43 loss: 5.4512\n",
            "====> Test set loss: 7.4088\n",
            "====> Epoch: 44 loss: 5.4161\n",
            "====> Test set loss: 7.5667\n",
            "====> Epoch: 45 loss: 5.3914\n",
            "====> Test set loss: 7.4981\n",
            "====> Epoch: 46 loss: 5.3221\n",
            "====> Test set loss: 7.4367\n",
            "====> Epoch: 47 loss: 5.2797\n",
            "====> Test set loss: 7.4903\n",
            "====> Epoch: 48 loss: 5.2786\n",
            "====> Test set loss: 7.3948\n",
            "====> Epoch: 49 loss: 5.1428\n",
            "====> Test set loss: 7.4414\n",
            "====> Epoch: 50 loss: 5.1460\n",
            "====> Test set loss: 7.4855\n",
            "====> Epoch: 51 loss: 5.1211\n",
            "====> Test set loss: 7.3859\n",
            "====> Epoch: 52 loss: 5.1016\n",
            "====> Test set loss: 7.5442\n",
            "====> Epoch: 53 loss: 5.0565\n",
            "====> Test set loss: 7.4065\n",
            "====> Epoch: 54 loss: 4.9757\n",
            "====> Test set loss: 7.3446\n",
            "====> Epoch: 55 loss: 4.9765\n",
            "====> Test set loss: 7.5030\n",
            "====> Epoch: 56 loss: 4.9080\n",
            "====> Test set loss: 7.4030\n",
            "====> Epoch: 57 loss: 4.9165\n",
            "====> Test set loss: 7.5656\n",
            "====> Epoch: 58 loss: 4.8253\n",
            "====> Test set loss: 7.5163\n",
            "====> Epoch: 59 loss: 4.8259\n",
            "====> Test set loss: 7.4362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-37de250ed01e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4d8fc122b580>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_losses, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-35c06ac5cef2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2econv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m#out = self.conv5_bn(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#out = F.max_pool2d(out, 2)  # 적용한 마지막 output kernel size, kernel 영향 + 풀링 영향으로 줄어든 사이즈\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-35c06ac5cef2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "Hmc1UoWF8_gP",
        "outputId": "05a5a50c-14b1-4620-b920-a68aab141059"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(np.array(vloss), label=\"valid\")\n",
        "plt.plot(np.array(tloss), label=\"train\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbdb8f49350>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql7wbGf5-LiJ",
        "outputId": "95d4134c-dae0-471f-fa56-c4875f5d9832"
      },
      "source": [
        "# RMSE\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cuda().float(), y.cuda()       \n",
        "        o = model(x)\n",
        "        loss = torch.sqrt(loss_function(o.squeeze(), y))\n",
        "        \n",
        "        test_loss += loss.item()\n",
        "print('====> Test set loss: {:.4f}'.format(test_loss / len(test_loader)))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Test set loss: 2.4765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz3tCr5EASYn",
        "outputId": "e95af10f-2cf9-492b-ec30-0d9b5680eddf"
      },
      "source": [
        "# R square\n",
        "o=model(x_val.cuda())\n",
        "r2(o.squeeze(), y_val.cuda())"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7974, device='cuda:0', grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kON6hc8zAUnf"
      },
      "source": [
        "#"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gakV_sJNAVBD",
        "outputId": "23590157-11c1-4264-ccb5-64edaeaa0b20"
      },
      "source": [
        "class E2EBlock(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, bias=False):\n",
        "        super(E2EBlock, self).__init__()\n",
        "        self.cnn1 = torch.nn.Conv2d(in_dim, out_dim, (1, 27), bias=bias)\n",
        "        self.cnn2 = torch.nn.Conv2d(in_dim, out_dim, (27, 1), bias=bias)\n",
        "\n",
        "        #nn.init.xavier_uniform_(self.cnn2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = self.cnn1(x)\n",
        "        b = self.cnn2(x)\n",
        "\n",
        "        return torch.cat([a]*27, 3) + torch.cat([b]*27, 2)\n",
        "\n",
        "class BrainNetCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrainNetCNN, self).__init__()\n",
        "        \n",
        "        self.e2econv1 = E2EBlock(1, 8, bias=True)\n",
        "        #self.conv5_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.E2N = torch.nn.Conv2d(8, 1, (1, 27))\n",
        "        self.N2G = torch.nn.Conv2d(1, 128, (27, 1))\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(128, 64)\n",
        "        self.fc2 = torch.nn.Linear(64, 1)\n",
        "        #self.dense5 = torch.nn.Linear(16, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = F.relu(self.e2econv1(x))\n",
        "        #out = self.conv5_bn(out)\n",
        "        #out = F.max_pool2d(out, 2)  # 적용한 마지막 output kernel size, kernel 영향 + 풀링 영향으로 줄어든 사이즈\n",
        "\n",
        "        x = F.relu(self.E2N(x))\n",
        "        x = F.relu(self.N2G(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        #x = self.dense4_bn(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def weights_init(m):\n",
        "    #if isinstance(m, nn.Conv2d):\n",
        "    #    nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "        #m.bias.data[0] = 9.0844\n",
        "        \n",
        "        #if m.bias is not None:\n",
        "        #  nn.init.constant_(m.bias.data, 10)\n",
        "        #nn.init.xavier_normal_(m.bias.data)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = BrainNetCNN().cuda()\n",
        "model.apply(weights_init)\n",
        "print(model)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BrainNetCNN(\n",
            "  (e2econv1): E2EBlock(\n",
            "    (cnn1): Conv2d(1, 8, kernel_size=(1, 27), stride=(1, 1))\n",
            "    (cnn2): Conv2d(1, 8, kernel_size=(27, 1), stride=(1, 1))\n",
            "  )\n",
            "  (E2N): Conv2d(8, 1, kernel_size=(1, 27), stride=(1, 1))\n",
            "  (N2G): Conv2d(1, 128, kernel_size=(27, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWWAyIOgGx6r",
        "outputId": "8b8018e9-3666-4aa4-9673-91c2b86aaed4"
      },
      "source": [
        "# the number of trainable parameter\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12570"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzmfl8BcG0IR",
        "outputId": "f544bcc8-6856-4b74-d553-2971100f5d0a"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)#5e-6\n",
        "loss_function = nn.MSELoss()\n",
        "epochs = 1\n",
        "\n",
        "# for loss plot\n",
        "tloss = []\n",
        "vloss = []\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    train(model, tloss, e)\n",
        "    test(model, vloss)\n",
        "\n",
        "y_pred = test_pred(model)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 loss: 3.8156\n",
            "====> Test set loss: 7.1315\n",
            "====> Test set loss: 7.1315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7qVbYHaG2fX",
        "outputId": "2b84fd39-7252-484c-bf2b-94a7c9bb62e8"
      },
      "source": [
        "# RMSE\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cuda().float(), y.cuda()       \n",
        "        o = model(x)\n",
        "        loss = torch.sqrt(loss_function(o.squeeze(), y))\n",
        "        \n",
        "        test_loss += loss.item()\n",
        "print('====> Test set loss: {:.4f}'.format(test_loss / len(test_loader)))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Test set loss: 2.4952\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARXnp58XG4nV",
        "outputId": "5f5744aa-cfb9-45c7-f029-e2b7bf375308"
      },
      "source": [
        "# R square\n",
        "o = model(x_val.cuda())\n",
        "r2(o.squeeze(), y_val.cuda())"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7950, device='cuda:0', grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyLM19RYHYQy"
      },
      "source": [
        "#"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyDQ-X_nH9iH",
        "outputId": "aeddeaa0-bb3f-4e7d-bb21-a14d06bee833"
      },
      "source": [
        "class E2EBlock(torch.nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, bias=False):\n",
        "        super(E2EBlock, self).__init__()\n",
        "        self.cnn1 = torch.nn.Conv2d(in_dim, out_dim, (1, 27), bias=bias)\n",
        "        self.cnn2 = torch.nn.Conv2d(in_dim, out_dim, (27, 1), bias=bias)\n",
        "\n",
        "        #nn.init.xavier_uniform_(self.cnn2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = self.cnn1(x)\n",
        "        b = self.cnn2(x)\n",
        "\n",
        "        return torch.cat([a]*27, 3) + torch.cat([b]*27, 2)\n",
        "\n",
        "class BrainNetCNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BrainNetCNN, self).__init__()\n",
        "        \n",
        "        self.e2econv1 = E2EBlock(1, 8, bias=True)\n",
        "        #self.conv5_bn = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.E2N = torch.nn.Conv2d(8, 1, (1, 27))\n",
        "        self.N2G = torch.nn.Conv2d(1, 16, (27, 1))\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(16, 8)\n",
        "        self.fc2 = torch.nn.Linear(8, 4)\n",
        "        self.fc3 = torch.nn.Linear(4, 2)\n",
        "        self.fc4 = torch.nn.Linear(2, 2)\n",
        "        self.fc5 = torch.nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = F.relu(self.e2econv1(x))\n",
        "        #out = self.conv5_bn(out)\n",
        "        #out = F.max_pool2d(out, 2)  # 적용한 마지막 output kernel size, kernel 영향 + 풀링 영향으로 줄어든 사이즈\n",
        "\n",
        "        x = F.relu(self.E2N(x))\n",
        "        x = F.relu(self.N2G(x))\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        \n",
        "        #x = self.dense4_bn(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def weights_init(m):\n",
        "    #if isinstance(m, nn.Conv2d):\n",
        "    #    nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight.data, nn.init.calculate_gain('relu'))\n",
        "        #m.bias.data[0] = 9.0844\n",
        "        \n",
        "        #if m.bias is not None:\n",
        "        #  nn.init.constant_(m.bias.data, 10)\n",
        "        #nn.init.xavier_normal_(m.bias.data)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = BrainNetCNN().cuda()\n",
        "model.apply(weights_init)\n",
        "print(model)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BrainNetCNN(\n",
            "  (e2econv1): E2EBlock(\n",
            "    (cnn1): Conv2d(1, 8, kernel_size=(1, 27), stride=(1, 1))\n",
            "    (cnn2): Conv2d(1, 8, kernel_size=(27, 1), stride=(1, 1))\n",
            "  )\n",
            "  (E2N): Conv2d(8, 1, kernel_size=(1, 27), stride=(1, 1))\n",
            "  (N2G): Conv2d(1, 16, kernel_size=(27, 1), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (fc3): Linear(in_features=4, out_features=2, bias=True)\n",
            "  (fc4): Linear(in_features=2, out_features=2, bias=True)\n",
            "  (fc5): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lklO9PWyH_KY",
        "outputId": "e916f132-5e5f-424b-e266-bba6decf7b38"
      },
      "source": [
        "# the number of trainable parameter\n",
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1304"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvK-uVphICKR",
        "outputId": "d9ff99f9-fec4-437d-a870-57d35a231f3e"
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)#5e-6\n",
        "loss_function = nn.MSELoss()\n",
        "epochs = 100 #33 #37 #33 #28 #37 #51  \n",
        "\n",
        "# for loss plot\n",
        "tloss = []\n",
        "vloss = []\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    train(model, tloss, e)\n",
        "    test(model, vloss)\n",
        "\n",
        "y_pred = test_pred(model)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 loss: 114.2715\n",
            "====> Test set loss: 110.4504\n",
            "====> Epoch: 2 loss: 107.9020\n",
            "====> Test set loss: 104.1856\n",
            "====> Epoch: 3 loss: 101.9924\n",
            "====> Test set loss: 98.3522\n",
            "====> Epoch: 4 loss: 96.4345\n",
            "====> Test set loss: 92.8169\n",
            "====> Epoch: 5 loss: 91.2231\n",
            "====> Test set loss: 87.6600\n",
            "====> Epoch: 6 loss: 86.3654\n",
            "====> Test set loss: 82.8486\n",
            "====> Epoch: 7 loss: 81.8202\n",
            "====> Test set loss: 78.3557\n",
            "====> Epoch: 8 loss: 77.5770\n",
            "====> Test set loss: 74.1175\n",
            "====> Epoch: 9 loss: 73.6050\n",
            "====> Test set loss: 70.1863\n",
            "====> Epoch: 10 loss: 69.9087\n",
            "====> Test set loss: 66.5144\n",
            "====> Epoch: 11 loss: 66.4872\n",
            "====> Test set loss: 63.0936\n",
            "====> Epoch: 12 loss: 63.3223\n",
            "====> Test set loss: 59.9670\n",
            "====> Epoch: 13 loss: 60.4224\n",
            "====> Test set loss: 57.0837\n",
            "====> Epoch: 14 loss: 57.7447\n",
            "====> Test set loss: 54.4244\n",
            "====> Epoch: 15 loss: 55.2878\n",
            "====> Test set loss: 51.9822\n",
            "====> Epoch: 16 loss: 53.0515\n",
            "====> Test set loss: 49.7479\n",
            "====> Epoch: 17 loss: 51.0250\n",
            "====> Test set loss: 47.7276\n",
            "====> Epoch: 18 loss: 49.2174\n",
            "====> Test set loss: 45.9408\n",
            "====> Epoch: 19 loss: 47.6069\n",
            "====> Test set loss: 44.3203\n",
            "====> Epoch: 20 loss: 46.1866\n",
            "====> Test set loss: 42.9142\n",
            "====> Epoch: 21 loss: 44.9424\n",
            "====> Test set loss: 41.6730\n",
            "====> Epoch: 22 loss: 43.8532\n",
            "====> Test set loss: 40.5783\n",
            "====> Epoch: 23 loss: 42.9079\n",
            "====> Test set loss: 39.6366\n",
            "====> Epoch: 24 loss: 42.0943\n",
            "====> Test set loss: 38.8155\n",
            "====> Epoch: 25 loss: 41.4060\n",
            "====> Test set loss: 38.1177\n",
            "====> Epoch: 26 loss: 40.8356\n",
            "====> Test set loss: 37.5427\n",
            "====> Epoch: 27 loss: 40.3597\n",
            "====> Test set loss: 37.0507\n",
            "====> Epoch: 28 loss: 39.9691\n",
            "====> Test set loss: 36.6600\n",
            "====> Epoch: 29 loss: 39.6498\n",
            "====> Test set loss: 36.3239\n",
            "====> Epoch: 30 loss: 39.3869\n",
            "====> Test set loss: 36.0455\n",
            "====> Epoch: 31 loss: 39.1731\n",
            "====> Test set loss: 35.8144\n",
            "====> Epoch: 32 loss: 39.0041\n",
            "====> Test set loss: 35.6222\n",
            "====> Epoch: 33 loss: 38.8671\n",
            "====> Test set loss: 35.4784\n",
            "====> Epoch: 34 loss: 38.7579\n",
            "====> Test set loss: 35.3537\n",
            "====> Epoch: 35 loss: 38.6738\n",
            "====> Test set loss: 35.2546\n",
            "====> Epoch: 36 loss: 38.6087\n",
            "====> Test set loss: 35.1723\n",
            "====> Epoch: 37 loss: 38.5565\n",
            "====> Test set loss: 35.1080\n",
            "====> Epoch: 38 loss: 38.5152\n",
            "====> Test set loss: 35.0597\n",
            "====> Epoch: 39 loss: 38.4859\n",
            "====> Test set loss: 35.0158\n",
            "====> Epoch: 40 loss: 38.4608\n",
            "====> Test set loss: 34.9807\n",
            "====> Epoch: 41 loss: 38.4424\n",
            "====> Test set loss: 34.9542\n",
            "====> Epoch: 42 loss: 38.4285\n",
            "====> Test set loss: 34.9307\n",
            "====> Epoch: 43 loss: 38.4167\n",
            "====> Test set loss: 34.9090\n",
            "====> Epoch: 44 loss: 38.4080\n",
            "====> Test set loss: 34.8945\n",
            "====> Epoch: 45 loss: 38.4012\n",
            "====> Test set loss: 34.8831\n",
            "====> Epoch: 46 loss: 38.3959\n",
            "====> Test set loss: 34.8724\n",
            "====> Epoch: 47 loss: 38.3918\n",
            "====> Test set loss: 34.8657\n",
            "====> Epoch: 48 loss: 38.3892\n",
            "====> Test set loss: 34.8554\n",
            "====> Epoch: 49 loss: 38.3863\n",
            "====> Test set loss: 34.8516\n",
            "====> Epoch: 50 loss: 38.3845\n",
            "====> Test set loss: 34.8467\n",
            "====> Epoch: 51 loss: 38.3823\n",
            "====> Test set loss: 34.8406\n",
            "====> Epoch: 52 loss: 38.3820\n",
            "====> Test set loss: 34.8358\n",
            "====> Epoch: 53 loss: 38.3811\n",
            "====> Test set loss: 34.8345\n",
            "====> Epoch: 54 loss: 38.3809\n",
            "====> Test set loss: 34.8315\n",
            "====> Epoch: 55 loss: 38.3790\n",
            "====> Test set loss: 34.8285\n",
            "====> Epoch: 56 loss: 38.3785\n",
            "====> Test set loss: 34.8262\n",
            "====> Epoch: 57 loss: 38.3778\n",
            "====> Test set loss: 34.8244\n",
            "====> Epoch: 58 loss: 38.3779\n",
            "====> Test set loss: 34.8239\n",
            "====> Epoch: 59 loss: 38.3785\n",
            "====> Test set loss: 34.8220\n",
            "====> Epoch: 60 loss: 38.3781\n",
            "====> Test set loss: 34.8211\n",
            "====> Epoch: 61 loss: 38.3779\n",
            "====> Test set loss: 34.8196\n",
            "====> Epoch: 62 loss: 38.3782\n",
            "====> Test set loss: 34.8193\n",
            "====> Epoch: 63 loss: 38.3770\n",
            "====> Test set loss: 34.8176\n",
            "====> Epoch: 64 loss: 38.3784\n",
            "====> Test set loss: 34.8180\n",
            "====> Epoch: 65 loss: 38.3776\n",
            "====> Test set loss: 34.8173\n",
            "====> Epoch: 66 loss: 38.3779\n",
            "====> Test set loss: 34.8169\n",
            "====> Epoch: 67 loss: 38.3778\n",
            "====> Test set loss: 34.8169\n",
            "====> Epoch: 68 loss: 38.3778\n",
            "====> Test set loss: 34.8165\n",
            "====> Epoch: 69 loss: 38.3771\n",
            "====> Test set loss: 34.8160\n",
            "====> Epoch: 70 loss: 38.3768\n",
            "====> Test set loss: 34.8149\n",
            "====> Epoch: 71 loss: 38.3764\n",
            "====> Test set loss: 34.8151\n",
            "====> Epoch: 72 loss: 38.3775\n",
            "====> Test set loss: 34.8153\n",
            "====> Epoch: 73 loss: 38.3777\n",
            "====> Test set loss: 34.8134\n",
            "====> Epoch: 74 loss: 38.3772\n",
            "====> Test set loss: 34.8131\n",
            "====> Epoch: 75 loss: 38.3781\n",
            "====> Test set loss: 34.8151\n",
            "====> Epoch: 76 loss: 38.3775\n",
            "====> Test set loss: 34.8132\n",
            "====> Epoch: 77 loss: 38.3773\n",
            "====> Test set loss: 34.8126\n",
            "====> Epoch: 78 loss: 38.3772\n",
            "====> Test set loss: 34.8133\n",
            "====> Epoch: 79 loss: 38.3776\n",
            "====> Test set loss: 34.8128\n",
            "====> Epoch: 80 loss: 38.3773\n",
            "====> Test set loss: 34.8129\n",
            "====> Epoch: 81 loss: 38.3771\n",
            "====> Test set loss: 34.8127\n",
            "====> Epoch: 82 loss: 38.3784\n",
            "====> Test set loss: 34.8117\n",
            "====> Epoch: 83 loss: 38.3769\n",
            "====> Test set loss: 34.8117\n",
            "====> Epoch: 84 loss: 38.3772\n",
            "====> Test set loss: 34.8115\n",
            "====> Epoch: 85 loss: 38.3775\n",
            "====> Test set loss: 34.8118\n",
            "====> Epoch: 86 loss: 38.3773\n",
            "====> Test set loss: 34.8114\n",
            "====> Epoch: 87 loss: 38.3769\n",
            "====> Test set loss: 34.8116\n",
            "====> Epoch: 88 loss: 38.3774\n",
            "====> Test set loss: 34.8132\n",
            "====> Epoch: 89 loss: 38.3771\n",
            "====> Test set loss: 34.8123\n",
            "====> Epoch: 90 loss: 38.3787\n",
            "====> Test set loss: 34.8132\n",
            "====> Epoch: 91 loss: 38.3765\n",
            "====> Test set loss: 34.8126\n",
            "====> Epoch: 92 loss: 38.3760\n",
            "====> Test set loss: 34.8131\n",
            "====> Epoch: 93 loss: 38.3778\n",
            "====> Test set loss: 34.8112\n",
            "====> Epoch: 94 loss: 38.3774\n",
            "====> Test set loss: 34.8130\n",
            "====> Epoch: 95 loss: 38.3786\n",
            "====> Test set loss: 34.8123\n",
            "====> Epoch: 96 loss: 38.3781\n",
            "====> Test set loss: 34.8124\n",
            "====> Epoch: 97 loss: 38.3774\n",
            "====> Test set loss: 34.8113\n",
            "====> Epoch: 98 loss: 38.3773\n",
            "====> Test set loss: 34.8118\n",
            "====> Epoch: 99 loss: 38.3772\n",
            "====> Test set loss: 34.8117\n",
            "====> Epoch: 100 loss: 38.3787\n",
            "====> Test set loss: 34.8114\n",
            "====> Test set loss: 34.8114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XclfCfxVjP88",
        "outputId": "8f79a664-9f6e-4ab4-ea18-1e51efe5b86c"
      },
      "source": [
        "np.argmin(vloss) + 1"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUL6-dCWIEFF",
        "outputId": "92e9fc4c-b895-4a76-f80d-966ddc569be4"
      },
      "source": [
        "# RMSE\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cuda().float(), y.cuda()       \n",
        "        o = model(x)\n",
        "        loss = torch.sqrt(loss_function(o.squeeze(), y))\n",
        "        \n",
        "        test_loss += loss.item()\n",
        "print('====> Test set loss: {:.4f}'.format(test_loss / len(test_loader)))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Test set loss: 5.5550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi2IZnodIFNK",
        "outputId": "4abc883c-d3c5-4cbd-9a6e-21436a5f864d"
      },
      "source": [
        "# R square\n",
        "o = model(x_val.cuda())\n",
        "r2(o.squeeze(), y_val.cuda())"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0009, device='cuda:0', grad_fn=<RsubBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "xQER9pAUIGhK",
        "outputId": "7e6daeb7-ef60-4e7a-b482-1b1b3632461f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(np.array(vloss), label=\"valid\")\n",
        "plt.plot(np.array(tloss), label=\"train\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7fa4c2ca10>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1uqwvC4KROm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}